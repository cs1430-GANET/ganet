{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cs1430-GANET/ganet/blob/main/monet_to_picasso.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9qVwUPSHsTU"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_addons\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from google.colab import drive\n",
        "import tensorflow_addons as tfa\n",
        "from keras import layers\n",
        "from keras import models\n",
        "import cv2\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4ohUX2IWDmg"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Device:', tpu.master())\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "except:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "print('Number of replicas:', strategy.num_replicas_in_sync)\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "    \n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCqC1Tgm1Hie"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXvu_swtTlM0"
      },
      "outputs": [],
      "source": [
        "drive._mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "TDt_mJxr-rei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 5\n",
        "img_height = 256\n",
        "img_width = 256"
      ],
      "metadata": {
        "id": "wGJcFQIs-qLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "monet_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  'drive/My Drive/Brown/Fall2021/1430/Project/monet_jpg/',\n",
        "  label_mode = None,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "normalization_layer = tf.keras.layers.Rescaling(scale=1./127.5, offset=-1)\n",
        "\n",
        "normalized_monet_ds = monet_ds.map(lambda x: (normalization_layer(x)))\n",
        "image_batch = next(iter(normalized_monet_ds))\n",
        "first_image = image_batch[0]\n",
        "print(np.min(first_image), np.max(first_image))\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "normalized_monet_ds = normalized_monet_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "yzmUsrJl-qIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "photo_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  'drive/My Drive/Brown/Fall2021/1430/Project/Pablo_Picasso/',\n",
        "  label_mode =None,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "normalized_photo_ds = photo_ds.map(lambda x: (normalization_layer(x)))\n",
        "image_batch = next(iter(normalized_photo_ds))\n",
        "first_image = image_batch[0]\n",
        "print(np.min(first_image), np.max(first_image))\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "normalized_photo_ds = normalized_photo_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "Zpdtm9KoB3or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGGtPYVIWIfb"
      },
      "outputs": [],
      "source": [
        "example_monet = next(iter(normalized_monet_ds))\n",
        "example_photo = next(iter(normalized_photo_ds))\n",
        "print(example_monet.shape)\n",
        "print(example_photo.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiQzCHfFWKkt"
      },
      "outputs": [],
      "source": [
        "plt.subplot(121)\n",
        "plt.title('Photo')\n",
        "plt.imshow(example_photo[4] * 0.5 + 0.5)  \n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title('Monet')\n",
        "plt.imshow(example_monet[4] * 0.5 + 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuZMh6y0iZQL"
      },
      "source": [
        "**U-Net Architecture for Generator**\n",
        "\n",
        "Each generator network is consists of encoder and decoder. Each encoder block is consist of three layers (Conv -> BatchNorm -> Leakyrelu). And each block in decoder network is consist of four layers (Transposed Conv -> BatchNorm -> Dropout -> Relu). The generator will take an image as input and outputs a generated image.\n",
        "\n",
        "*We are doing instanceNorm instead of batchNorm*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLJdZlrLW3X8"
      },
      "outputs": [],
      "source": [
        "def downsample(filters, size, apply_instancenorm=True):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "    result = keras.Sequential()\n",
        "    result.add(layers.Conv2D(filters, size, strides=2, padding='same',\n",
        "                             kernel_initializer=initializer, use_bias=False))\n",
        "\n",
        "    if apply_instancenorm:\n",
        "        result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n",
        "\n",
        "    result.add(layers.LeakyReLU())\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMFwnActiBEh"
      },
      "outputs": [],
      "source": [
        "def upsample(filters, size, apply_dropout=False):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "    result = keras.Sequential()\n",
        "    result.add(layers.Conv2DTranspose(filters, size, strides=2,\n",
        "                                      padding='same',\n",
        "                                      kernel_initializer=initializer,\n",
        "                                      use_bias=False))\n",
        "\n",
        "    result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n",
        "\n",
        "    if apply_dropout:\n",
        "        result.add(layers.Dropout(0.5))\n",
        "\n",
        "    result.add(layers.ReLU())\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvnbW-ccjKXu"
      },
      "source": [
        "The generator first downsamples the input image and then upsample while establishing long skip connections. Skip connections are a way to help bypass the vanishing gradient problem by concatenating the output of a layer to multiple layers instead of only one. Here we concatenate the output of the downsample layer to the upsample layer in a symmetrical fashion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSqlnjKTjNGC"
      },
      "outputs": [],
      "source": [
        "OUTPUT_CHANNELS = 3\n",
        "\n",
        "def Generator():\n",
        "    inputs = layers.Input(shape=[256,256,3])\n",
        "\n",
        "    # bs = batch size\n",
        "    down_stack = [\n",
        "        downsample(64, 4, apply_instancenorm=False), # (bs, 128, 128, 64)\n",
        "        downsample(128, 4), # (bs, 64, 64, 128)\n",
        "        downsample(256, 4), # (bs, 32, 32, 256)\n",
        "        downsample(512, 4), # (bs, 16, 16, 512)\n",
        "        downsample(512, 4), # (bs, 8, 8, 512)\n",
        "        downsample(512, 4), # (bs, 4, 4, 512)\n",
        "        downsample(512, 4), # (bs, 2, 2, 512)\n",
        "        downsample(512, 4), # (bs, 1, 1, 512)\n",
        "    ]\n",
        "\n",
        "    up_stack = [\n",
        "        upsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n",
        "        upsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n",
        "        upsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n",
        "        upsample(512, 4), # (bs, 16, 16, 1024)\n",
        "        upsample(256, 4), # (bs, 32, 32, 512)\n",
        "        upsample(128, 4), # (bs, 64, 64, 256)\n",
        "        upsample(64, 4), # (bs, 128, 128, 128)\n",
        "    ]\n",
        "\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    last = layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\n",
        "                                  strides=2,\n",
        "                                  padding='same',\n",
        "                                  kernel_initializer=initializer,\n",
        "                                  activation='tanh') # (bs, 256, 256, 3)\n",
        "\n",
        "    x = inputs\n",
        "\n",
        "    # Downsampling through the model\n",
        "    skips = []\n",
        "    for down in down_stack:\n",
        "        x = down(x)\n",
        "        skips.append(x)\n",
        "\n",
        "    skips = reversed(skips[:-1])\n",
        "\n",
        "    # Upsampling and establishing the skip connections\n",
        "    for up, skip in zip(up_stack, skips):\n",
        "        x = up(x)\n",
        "        x = layers.Concatenate()([x, skip])\n",
        "\n",
        "    x = last(x)\n",
        "\n",
        "    return keras.Model(inputs=inputs, outputs=x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Nd_RoPvkZLS"
      },
      "source": [
        "The discriminator takes in the input image and classifies it as real or fake (generated). Instead of outputing a single node, the discriminator outputs a smaller 2D image with higher pixel values indicating a real classification and lower values indicating a fake classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R8DICbwokaAO"
      },
      "outputs": [],
      "source": [
        "def Discriminator():\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
        "\n",
        "    inp = layers.Input(shape=[256, 256, 3], name='input_image')\n",
        "\n",
        "    x = inp\n",
        "\n",
        "    down1 = downsample(64, 4, False)(x) # (bs, 128, 128, 64)\n",
        "    down2 = downsample(128, 4)(down1) # (bs, 64, 64, 128)\n",
        "    down3 = downsample(256, 4)(down2) # (bs, 32, 32, 256)\n",
        "\n",
        "    zero_pad1 = layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n",
        "    conv = layers.Conv2D(512, 4, strides=1,\n",
        "                         kernel_initializer=initializer,\n",
        "                         use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
        "\n",
        "    norm1 = tfa.layers.InstanceNormalization(gamma_initializer=gamma_init)(conv)\n",
        "\n",
        "    leaky_relu = layers.LeakyReLU()(norm1)\n",
        "\n",
        "    zero_pad2 = layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
        "\n",
        "    last = layers.Conv2D(1, 4, strides=1,\n",
        "                         kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
        "\n",
        "    return tf.keras.Model(inputs=inp, outputs=last)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nv0eEF17lyUM"
      },
      "source": [
        "Use tf.distribute.Strategy.scope to specify that a strategy should be used when building an executing your model. (This puts you in the \"cross-replica context\" for this strategy, which means the strategy is put in control of things like variable placement.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAkSQCk4lyvN"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    monet_generator = Generator() # transforms photos to Monet-esque paintings\n",
        "    photo_generator = Generator() # transforms Monet paintings to be more like photos\n",
        "\n",
        "    monet_discriminator = Discriminator() # differentiates real Monet paintings and generated Monet paintings\n",
        "    photo_discriminator = Discriminator() # differentiates real photos and generated photos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pC62S0ugmP-Z"
      },
      "outputs": [],
      "source": [
        "plt.subplot(121)\n",
        "plt.title('Photo')\n",
        "plt.imshow(example_photo[4] * 0.5 + 0.5)\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.title('Monet')\n",
        "plt.imshow( example_monet[4] * 0.5 + 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asy8WUcomSwi"
      },
      "source": [
        "** UN-TRAINED TRY **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgUeRJeqmLMY"
      },
      "outputs": [],
      "source": [
        "to_monet = monet_generator(example_photo)\n",
        "plt.figure(figsize=(14.5, 8.5))\n",
        "plt.subplot(1, 2, 1)\n",
        "\n",
        "plt.title(\"Original Photo\")\n",
        "plt.imshow(example_photo[2] * 0.5 + 0.5)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Monet-esque Photo\")\n",
        "plt.imshow(to_monet[2] * 0.5 + 0.5)\n",
        "plt.savefig(\"drive/My Drive/Brown/Fall2021/1430/Project/picasso_output/output_\"+str(00)+\".png\", dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ethVYGJxmeGk"
      },
      "source": [
        "Since our generators are not trained yet, the generated Monet-esque photo does not show what is expected at this point."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTCSSLQmP7s5"
      },
      "source": [
        "**CYCLE-GAN MODEL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSIjaK5KQ3lI"
      },
      "source": [
        "During the training step, the model transforms a photo to a Monet painting and then back to a photo. The difference between the original photo and the twice-transformed photo is the cycle-consistency loss. We want the original photo and the twice-transformed photo to be similar to one another."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbJwQbocQ33c"
      },
      "outputs": [],
      "source": [
        "class CycleGan(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        monet_generator,\n",
        "        photo_generator,\n",
        "        monet_discriminator,\n",
        "        photo_discriminator,\n",
        "        lambda_cycle=10,\n",
        "    ):\n",
        "        super(CycleGan, self).__init__()\n",
        "        self.m_gen = monet_generator\n",
        "        self.p_gen = photo_generator\n",
        "        self.m_disc = monet_discriminator\n",
        "        self.p_disc = photo_discriminator\n",
        "        self.lambda_cycle = lambda_cycle\n",
        "        \n",
        "    def compile(\n",
        "        self,\n",
        "        m_gen_optimizer,\n",
        "        p_gen_optimizer,\n",
        "        m_disc_optimizer,\n",
        "        p_disc_optimizer,\n",
        "        gen_loss_fn,\n",
        "        disc_loss_fn,\n",
        "        cycle_loss_fn,\n",
        "        identity_loss_fn\n",
        "    ):\n",
        "        super(CycleGan, self).compile()\n",
        "        self.m_gen_optimizer = m_gen_optimizer\n",
        "        self.p_gen_optimizer = p_gen_optimizer\n",
        "        self.m_disc_optimizer = m_disc_optimizer\n",
        "        self.p_disc_optimizer = p_disc_optimizer\n",
        "        self.gen_loss_fn = gen_loss_fn\n",
        "        self.disc_loss_fn = disc_loss_fn\n",
        "        self.cycle_loss_fn = cycle_loss_fn\n",
        "        self.identity_loss_fn = identity_loss_fn\n",
        "    \n",
        "    def train_step(self, batch_data):\n",
        "        real_monet, real_photo = batch_data\n",
        "        \n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            # photo to monet back to photo\n",
        "            fake_monet = self.m_gen(real_photo, training=True)\n",
        "            cycled_photo = self.p_gen(fake_monet, training=True)\n",
        "\n",
        "            # monet to photo back to monet\n",
        "            fake_photo = self.p_gen(real_monet, training=True)\n",
        "            cycled_monet = self.m_gen(fake_photo, training=True)\n",
        "\n",
        "            # generating itself\n",
        "            same_monet = self.m_gen(real_monet, training=True)\n",
        "            same_photo = self.p_gen(real_photo, training=True)\n",
        "\n",
        "            # discriminator used to check, inputing real images\n",
        "            disc_real_monet = self.m_disc(real_monet, training=True)\n",
        "            disc_real_photo = self.p_disc(real_photo, training=True)\n",
        "\n",
        "            # discriminator used to check, inputing fake images\n",
        "            disc_fake_monet = self.m_disc(fake_monet, training=True)\n",
        "            disc_fake_photo = self.p_disc(fake_photo, training=True)\n",
        "\n",
        "            # evaluates generator loss\n",
        "            monet_gen_loss = self.gen_loss_fn(disc_fake_monet)\n",
        "            photo_gen_loss = self.gen_loss_fn(disc_fake_photo)\n",
        "\n",
        "            # evaluates total cycle consistency loss\n",
        "            total_cycle_loss = self.cycle_loss_fn(real_monet, cycled_monet, self.lambda_cycle) + self.cycle_loss_fn(real_photo, cycled_photo, self.lambda_cycle)\n",
        "\n",
        "            # evaluates total generator loss\n",
        "            total_monet_gen_loss = monet_gen_loss + total_cycle_loss + self.identity_loss_fn(real_monet, same_monet, self.lambda_cycle)\n",
        "            total_photo_gen_loss = photo_gen_loss + total_cycle_loss + self.identity_loss_fn(real_photo, same_photo, self.lambda_cycle)\n",
        "\n",
        "            # evaluates discriminator loss\n",
        "            monet_disc_loss = self.disc_loss_fn(disc_real_monet, disc_fake_monet)\n",
        "            photo_disc_loss = self.disc_loss_fn(disc_real_photo, disc_fake_photo)\n",
        "\n",
        "        # Calculate the gradients for generator and discriminator\n",
        "        monet_generator_gradients = tape.gradient(total_monet_gen_loss,\n",
        "                                                  self.m_gen.trainable_variables)\n",
        "        photo_generator_gradients = tape.gradient(total_photo_gen_loss,\n",
        "                                                  self.p_gen.trainable_variables)\n",
        "\n",
        "        monet_discriminator_gradients = tape.gradient(monet_disc_loss,\n",
        "                                                      self.m_disc.trainable_variables)\n",
        "        photo_discriminator_gradients = tape.gradient(photo_disc_loss,\n",
        "                                                      self.p_disc.trainable_variables)\n",
        "\n",
        "        # Apply the gradients to the optimizer\n",
        "        self.m_gen_optimizer.apply_gradients(zip(monet_generator_gradients,\n",
        "                                                 self.m_gen.trainable_variables))\n",
        "\n",
        "        self.p_gen_optimizer.apply_gradients(zip(photo_generator_gradients,\n",
        "                                                 self.p_gen.trainable_variables))\n",
        "\n",
        "        self.m_disc_optimizer.apply_gradients(zip(monet_discriminator_gradients,\n",
        "                                                  self.m_disc.trainable_variables))\n",
        "        \n",
        "        self.p_disc_optimizer.apply_gradients(zip(photo_discriminator_gradients,\n",
        "                                                  self.p_disc.trainable_variables))\n",
        "        \n",
        "        return {\n",
        "            \"monet_gen_loss\": total_monet_gen_loss,\n",
        "            \"photo_gen_loss\": total_photo_gen_loss,\n",
        "            \"monet_disc_loss\": monet_disc_loss,\n",
        "            \"photo_disc_loss\": photo_disc_loss\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3JhMo1QiA21"
      },
      "source": [
        "**LOSS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgt5s_EfiOqw"
      },
      "source": [
        "The discriminator loss function below compares real images to a matrix of 1s and fake images to a matrix of 0s. The perfect discriminator will output all 1s for real images and all 0s for fake images. The discriminator loss outputs the average of the real and generated loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKzet8A9iAJ1"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    def discriminator_loss(real, generated):\n",
        "        real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(real), real)\n",
        "\n",
        "        # print(\"real_loss: \", real_loss)\n",
        "        # print(\"shape real_loss: \", real_loss.shape)\n",
        "\n",
        "        generated_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.zeros_like(generated), generated)\n",
        "\n",
        "        # print(\"generated_loss: \", generated_loss)\n",
        "        # print(\"shape generated_loss: \", generated_loss.shape)\n",
        "\n",
        "        total_disc_loss = real_loss + generated_loss\n",
        "\n",
        "        return total_disc_loss * 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu4EwrGMipCx"
      },
      "source": [
        "The generator wants to fool the discriminator into thinking the generated image is real. The perfect generator will have the discriminator output only 1s. Thus, it compares the generated image to a matrix of 1s to find the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhGkYdpdipX3"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    def generator_loss(generated):\n",
        "        # print(\"generator_loss returning\")\n",
        "\n",
        "        return tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(tf.ones_like(generated), generated)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtnD1_VTi4Kw"
      },
      "source": [
        "We want our original photo and the twice transformed photo to be similar to one another. Thus, we can calculate the cycle consistency loss by finding the average of their difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UTxvIeqi4iB"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    def calc_cycle_loss(real_image, cycled_image, LAMBDA):\n",
        "        loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
        "\n",
        "        # print(\"calc_cycle_loss returning\")\n",
        "\n",
        "        return LAMBDA * loss1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AMiCXxujKoJ"
      },
      "source": [
        "The identity loss compares the image with its generator (i.e. photo with photo generator). If given a photo as input, we want it to generate the same image as the image was originally a photo. The identity loss compares the input with the output of the generator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1LgwZ1njIjv"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    def identity_loss(real_image, same_image, LAMBDA):\n",
        "        loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
        "\n",
        "        # print(\"calc_cycle_loss returning\")\n",
        "        \n",
        "        return LAMBDA * 0.5 * loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eb4tJTOjVn2"
      },
      "source": [
        "**Training the Cycle-GAN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AefTlAwDjQcY"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    monet_generator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
        "    photo_generator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
        "\n",
        "    monet_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "    photo_discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zcp1Nw2jjjHy"
      },
      "outputs": [],
      "source": [
        "with strategy.scope():\n",
        "    cycle_gan_model = CycleGan(\n",
        "        monet_generator, photo_generator, monet_discriminator, photo_discriminator\n",
        "    )\n",
        "\n",
        "    cycle_gan_model.compile(\n",
        "        m_gen_optimizer = monet_generator_optimizer,\n",
        "        p_gen_optimizer = photo_generator_optimizer,\n",
        "        m_disc_optimizer = monet_discriminator_optimizer,\n",
        "        p_disc_optimizer = photo_discriminator_optimizer,\n",
        "        gen_loss_fn = generator_loss,\n",
        "        disc_loss_fn = discriminator_loss,\n",
        "        cycle_loss_fn = calc_cycle_loss,\n",
        "        identity_loss_fn = identity_loss\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YMhNUVPcirg"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = \"drive/My Drive/Brown/Fall2021/1430/Project/picasso_monet_training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "os.listdir('drive/My Drive/Brown/Fall2021/1430/Project/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1,\n",
        "                                                 save_freq='epoch', \n",
        "                                                 period=3)\n",
        "class CustomCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        # to_monet = monet_generator(tf.expand_dims(photo_data[0],axis=0))\n",
        "        to_monet = monet_generator(example_photo)\n",
        "        # plt.set_size_inches(18.5, 10.5)\n",
        "        plt.figure(figsize=(14.5, 8.5))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title(\"Picasso\")\n",
        "        plt.imshow(example_photo[0] * 0.5 + 0.5)\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.title(\"Monet-esque Photo Epoch:\"+str(epoch))\n",
        "        plt.imshow(to_monet[0] * 0.5 + 0.5)\n",
        "        plt.savefig(\"drive/My Drive/Brown/Fall2021/1430/Project/picasso_monet_output/output_\"+str(epoch)+\".png\", dpi=150)\n",
        "       \n",
        "\n",
        "history  = cycle_gan_model.fit(\n",
        "    tf.data.Dataset.zip((normalized_monet_ds, normalized_photo_ds)),\n",
        "    epochs=100,\n",
        "    callbacks=[cp_callback,CustomCallback()]\n",
        ")"
      ],
      "metadata": {
        "id": "31_jyIM_-Hvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_monet = photo_generator(example_monet)\n",
        "\n",
        "plt.figure(figsize=(18.5, 10.5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Monet\")\n",
        "plt.imshow(example_monet[0] * 0.5 + 0.5)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Picasso-esque Photo\")\n",
        "plt.imshow(to_monet[0] * 0.5 + 0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v8ULiFx9Lf3p"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "monet-to-picasso.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}